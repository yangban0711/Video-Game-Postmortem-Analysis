{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b08af45-9f81-4021-adb2-57b707e57dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job done-\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import mean_squared_error, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.svm import SVR, SVC\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('Job done-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb52fa-7ff1-4b7b-85f6-752515ecd9a8",
   "metadata": {},
   "source": [
    "#### 1. BERT 준비 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe2ef634-c39e-46da-8eef-23b180098829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job done\n"
     ]
    }
   ],
   "source": [
    "# 특정 단어에 대한 임베딩 얻기\n",
    "def get_embbeding_of_a_word(target_word: str, tokenizer, outputs, tokens):\n",
    "    try:\n",
    "        word_index = tokens['input_ids'][0].tolist().index(tokenizer.convert_tokens_to_ids(target_word))\n",
    "    \n",
    "        return outputs.last_hidden_state[:, word_index, :]\n",
    "    except Exception as exp:\n",
    "        return None\n",
    "    \n",
    "# 완료 표시\n",
    "print('Job done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d86c2-891b-4992-9655-34cd159069c7",
   "metadata": {},
   "source": [
    "#### 2. 워드 임베딩 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17f8c8e3-2c79-4182-9702-ac36ad936633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job done\n"
     ]
    }
   ],
   "source": [
    "total_file_path = \"data/dataset.txt\"\n",
    "total_documents = []\n",
    "total_document = []\n",
    "\n",
    "vector_size = 768\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "with open(total_file_path, 'r', encoding='utf-8') as file:\n",
    "    # Postmortum 읽기\n",
    "    for line in file:\n",
    "        # Document separation\n",
    "        if line == '\\n':\n",
    "            total_documents.append('\\n'.join(total_document))\n",
    "            total_document = []\n",
    "\n",
    "        # Add to document\n",
    "        total_document.append(line)\n",
    "\n",
    "    # For last game document\n",
    "    total_documents.append('\\n'.join(total_document))\n",
    "\n",
    "##print(total_documents)\n",
    "\n",
    "# 워드 임베딩\n",
    "total_document_vectors = np.array([]).reshape(0, vector_size)\n",
    "for total_document in total_documents:\n",
    "    document_vectors = np.array([]).reshape(0, vector_size)\n",
    "    \n",
    "    # tokenizing\n",
    "    tokens = tokenizer('\\n'.join(total_document),\n",
    "                       return_tensors='pt',\n",
    "                       max_length=512)\n",
    "    \n",
    "    # Word embedding\n",
    "    outputs = model(**tokens)\n",
    "        \n",
    "    # Feature vector of a document (game)\n",
    "    document_vectors = outputs.last_hidden_state.mean(axis=1)\n",
    "    \n",
    "    # Append to total document vector\n",
    "    total_document_vectors = np.vstack((total_document_vectors, document_vectors.detach().numpy()))\n",
    "    \n",
    "# Debug\n",
    "print('Job done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3d2a2-c3cd-46fc-adac-d1db4a8eda06",
   "metadata": {},
   "source": [
    "#### 3. 목표값 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb47f3b1-57fc-4203-a140-07d6f3cbfeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'tool', 'time', 'unrelated', 'planning', 'planning', 'unrelated', 'planning', 'planning', 'unrelated', 'communication', 'communication', 'communication', 'unrelated', 'unrelated', 'planning', 'planning', 'unrelated', 'optimization', 'optimization', 'unrelated', 'planning', 'planning', 'unrelated', 'unrelated', 'communication', 'communication', 'communication', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'testing', 'testing', 'unrelated', 'documentation', 'planning', 'documentation', 'documentation', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'team', 'team', 'time', 'planning', 'team', 'team', 'team', 'team', 'team', 'team', 'team', 'planning', 'planning', 'team', 'unrelated', 'team', 'team', 'team', 'team', 'team', 'team', 'team', 'unrelated', 'team', 'team', 'team', 'team', 'team', 'team', 'unrelated', 'feature', 'feature', 'team', 'feature', 'unrelated', 'feature', 'feature', 'feature', 'feature', 'bugs', 'bugs', 'bugs', 'bugs', 'bugs', 'communication', 'team', 'team', 'unrelated', 'design', 'design', 'design', 'design', 'unrelated', 'planning', 'team', 'testing', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'marketing', 'unrelated', 'unrelated', 'design', 'team', 'marketing', 'team', 'communication', 'unrelated', 'planning', 'team', 'design', 'feature', 'team', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'optimization', 'unrelated', 'communication', 'communication', 'bugs', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'planning', 'planning', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'unrelated', 'design', 'unrelated', 'design', 'unrelated', 'unrelated', 'design', 'design', 'design', 'unrelated', 'feature', 'feature', 'feature', 'tool', 'optimization', 'optimization', 'optimization', 'unrelated', 'optimization', 'unrelated', 'communication', 'marketing', 'unrelated', 'communication', 'communication', 'marketing', 'communication', 'marketing', 'unrelated', 'unrelated', 'unrelated', 'budget', 'budget', 'unrelated', 'budget', 'unrelated', 'unrelated', 'unrelated', 'team', 'unrelated', 'budget', 'team', 'unrelated', 'unrelated', 'feature', 'unrelated', 'unrelated', 'feature', 'testing', 'unrelated', 'unrelated', 'planning', 'testing', 'time', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'marketing', 'marketing', 'marketing', 'marketing', 'unrelated', 'marketing', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'team', 'team', 'design', 'team', 'team', 'unrelated', 'unrelated', 'communication', 'unrelated', 'unrelated', 'communication', 'marketing', 'unrelated', 'planning', 'tool', 'unrelated', 'unrelated', 'testing', 'testing', 'bugs', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'time', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'team', 'team', 'unrelated', 'design', 'team', 'unrelated', 'team', 'unrelated', 'planning', 'unrelated', 'planning', 'planning', 'planning', 'unrelated', 'tool', 'tool', 'feature', 'unrelated', 'unrelated', 'unrelated', 'tool', 'tool', 'tool', 'tool', 'unrelated', 'team', 'team', 'feature', 'communication', 'planning', 'feature', 'team', 'unrelated', 'team', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'time', 'time', 'budget', 'unrelated', 'design', 'unrelated', 'team', 'team', 'unrelated', 'unrelated', 'team', 'unrelated', 'unrelated', 'testing', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'planning', 'time', 'unrelated', 'communication', 'team', 'communication', 'unrelated', 'testing', 'testing', 'team', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'unrelated', 'design', 'design', 'design', 'design', 'tool', 'unrelated', 'design', 'design', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'design', 'testing', 'unrelated', 'tool', 'tool', 'unrelated', 'tool', 'tool', 'tool', 'tool', 'tool', 'team', 'planning', 'unrelated', 'feature', 'feature', 'feature', 'unrelated', 'unrelated', 'design', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'planning', 'planning', 'unrelated', 'planning', 'unrelated', 'optimization', 'optimization', 'unrelated', 'unrelated', 'unrelated', 'tool', 'unrelated', 'tool', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'design', 'unrelated', 'unrelated', 'design', 'design', 'design', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'feature', 'feature', 'unrelated', 'design', 'feature', 'feature', 'feature', 'unrelated', 'design', 'unrelated', 'design', 'feature', 'feature', 'feature', 'unrelated', 'unrelated', 'team', 'unrelated', 'documentation', 'documentation', 'documentation', 'documentation', 'documentation', 'documentation', 'documentation', 'documentation', 'documentation', 'team', 'team', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'design', 'unrelated', 'unrelated', 'design', 'unrelated', 'unrelated', 'unrelated', 'design', 'unrelated', 'design', 'design', 'design', 'design', 'unrelated', 'feature', 'feature', 'feature', 'feature', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'team', 'team', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'unrelated', 'time', 'communication', 'unrelated', 'unrelated', 'unrelated', 'design', 'design', 'design', 'design', 'communication', 'design', 'design', 'design', 'design', 'unrelated', 'tool', 'tool', 'tool', 'tool', 'unrelated', 'team', 'team', 'team', 'team', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'team', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'unrelated', 'unrelated', 'unrelated', 'team', 'testing', 'testing', 'testing', 'planning', 'planning', 'unrelated', 'communication', 'communication', 'communication', 'communication', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'design', 'unrelated', 'design', 'design', 'feature', 'testing', 'unrelated', 'marketing', 'marketing', 'marketing', 'team', 'communication', 'marketing', 'unrelated', 'unrelated', 'team', 'unrelated', 'communication', 'planning', 'unrelated', 'unrelated', 'unrelated', 'feature', 'feature', 'unrelated', 'optimization', 'design', 'unrelated', 'tool', 'tool', 'tool', 'tool', 'unrelated', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'unrelated', 'planning', 'design', 'planning', 'unrelated', 'unrelated', 'design', 'design', 'unrelated', 'optimization', 'optimization', 'optimization', 'optimization', 'unrelated', 'optimization', 'optimization', 'unrelated', 'optimization', 'optimization', 'unrelated', 'optimization', 'optimization', 'unrelated', 'unrelated']\n",
      "jobs finished b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hooni/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/classification.txt'\n",
    "class_list = []\n",
    "\n",
    "class_size = 28   ### 29 -> 28\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        class_type = str(line.strip())\n",
    "        class_list.append(class_type)\n",
    "        \n",
    "print(class_list)\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "class_list = ohe.fit_transform(np.array(class_list).reshape(-1, 1))\n",
    "\n",
    "label_size = class_list.shape[1]\n",
    "data_index = np.arange(1, total_document_vectors.shape[0] + 1).reshape(-1, 1)\n",
    "data = np.hstack((data_index, total_document_vectors, class_list))\n",
    "\n",
    "#debug\n",
    "print('jobs finished b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "767e8cd7-a73a-4a93-b8b7-839e8fc8e60c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Dimension: 781 -> 133\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "\n",
    "# 데이터 준비\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:, :vector_size + label_size],\n",
    "                                                    data[:, vector_size + label_size],\n",
    "                                                    test_size=test_ratio,\n",
    "                                                    stratify=data[:, vector_size + label_size],\n",
    "                                                    random_state=0)\n",
    "\n",
    "# 레이블 분리\n",
    "X_train_index, X_test_index = X_train[:, 0], X_test[:, 0]\n",
    "X_train, X_test = X_train[:, 1:], X_test[:, 1:]\n",
    "\n",
    "pca_var_ratio = 0.99\n",
    "pca = PCA(n_components=pca_var_ratio)\n",
    "original_dimension = X_train.shape[1]\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(f'Reduced Dimension: {original_dimension} -> {X_train.shape[1]}')\n",
    "\n",
    "# Result Preparation\n",
    "result_table = pd.DataFrame(columns=['index', 'type', 'model', 'truth', 'prediction', 'f1', 'auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a302380-4b5d-4572-8988-a22358753628",
   "metadata": {},
   "source": [
    "#### 4. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3de773-15ee-4f36-b8ea-4cda6c38172b",
   "metadata": {},
   "source": [
    "##### Experiment Design\n",
    "1. Word Embedding\n",
    "- TF-IDF\n",
    "- Word2Vec\n",
    "- Bert\n",
    "\n",
    "2. Classfier\n",
    "- Logistic Regression\n",
    "- SVM (Support Vector Machine)\n",
    "- RF (Random Forest)\n",
    "- XGBoost (Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b295a10-bc42-489c-bfb0-98fa7635cd2c",
   "metadata": {},
   "source": [
    "4-1 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0918149f-eb99-4b04-90eb-a1dee56677bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for LR training: 0.00 min\n",
      "[LR 학습 데이터]\n",
      "y_train=array([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "       1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 1., 0.])\n",
      "train_prediction=array([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "       1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 1., 0.])\n",
      "result: f1=0.998, auc=0.998\n",
      "[LR 검증 데이터]\n",
      "y_test=array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "       1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "test_prediction=array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "       1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "result: f1=0.970, auc=0.970\n"
     ]
    }
   ],
   "source": [
    "# LR 학습\n",
    "timer = time.time()\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(f'Elapsed time for LR training: {(time.time() - timer)/60:0.2f} min')\n",
    "\n",
    "# LR 학습데이터 추론\n",
    "print('[LR 학습 데이터]')\n",
    "train_prediction = lr_model.predict(X_train)\n",
    "print(f'{y_train=}')\n",
    "print(f'{train_prediction=}')\n",
    "f1 = f1_score(y_train, train_prediction, average='weighted')\n",
    "auc = roc_auc_score(y_train, train_prediction)\n",
    "for index in range(train_prediction.shape[0]):\n",
    "    result_table.loc[result_table.shape[0]] = [X_train_index[index], 'train', 'LR', y_train[index], train_prediction[index],\n",
    "                                               f1_score(y_train, train_prediction, average='weighted'),\n",
    "                                               roc_auc_score(y_train, train_prediction)]\n",
    "print(f'result: {f1=:0.3f}, {auc=:0.3f}')\n",
    "\n",
    "# LR 추론\n",
    "print('[LR 검증 데이터]')\n",
    "test_prediction = lr_model.predict(X_test)\n",
    "print(f'{y_test=}')\n",
    "print(f'{test_prediction=}')\n",
    "f1 = f1_score(y_test, test_prediction, average='weighted')\n",
    "auc = roc_auc_score(y_test, test_prediction)\n",
    "for index in range(test_prediction.shape[0]):\n",
    "    result_table.loc[result_table.shape[0]] = [X_test_index[index], 'test', 'LR', y_test[index], test_prediction[index],\n",
    "                                               f1_score(y_test, test_prediction, average='weighted'),\n",
    "                                               roc_auc_score(y_test, test_prediction)]\n",
    "print(f'result: {f1=:0.3f}, {auc=:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdbd63-4a66-4002-8551-a3199c1d7809",
   "metadata": {},
   "source": [
    "4-2 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "156500b1-c6e0-4f54-92ab-314ec24c020a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hooni/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/hooni/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for SVC optimization: 0.19 min\n",
      "최적의 하이퍼파라미터: OrderedDict([('C', 230), ('gamma', 0.01)])\n",
      "Elapsed time for SVC training: 0.00 min\n",
      "[SVC 학습 데이터]\n",
      "y_train=array([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "       1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 1., 0.])\n",
      "train_prediction=array([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "       0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "       1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 1., 0.])\n",
      "result: f1=1.000, auc=1.000\n",
      "[SVC 검증 데이터]\n",
      "y_test=array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "       1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "test_prediction=array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "       1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "result: f1=1.000, auc=1.000\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'C': (1, 10000),\n",
    "    'gamma': (0.01, 1.0)\n",
    "}\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "opt = BayesSearchCV(svc_rbf, param_space, n_iter=50, cv=10, n_jobs=-1, n_points=8, verbose=0)\n",
    "\n",
    "timer = time.time()\n",
    "opt.fit(X_train, y_train)\n",
    "print(f'Elapsed time for SVC optimization: {(time.time() - timer)/60:0.2f} min')\n",
    "print(\"최적의 하이퍼파라미터:\", opt.best_params_)\n",
    "\n",
    "# SVC 학습\n",
    "timer = time.time()\n",
    "svc_rbf = SVC(kernel='rbf', **opt.best_params_)\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "print(f'Elapsed time for SVC training: {(time.time() - timer)/60:0.2f} min')\n",
    "\n",
    "# SVC 학습데이터 추론\n",
    "print('[SVC 학습 데이터]')\n",
    "train_prediction = svc_rbf.predict(X_train)\n",
    "print(f'{y_train=}')\n",
    "print(f'{train_prediction=}')\n",
    "f1 = f1_score(y_train, train_prediction, average='weighted')\n",
    "auc = roc_auc_score(y_train, train_prediction) ####################one_hot_encoding 제외\n",
    "for index in range(train_prediction.shape[0]):\n",
    "    result_table.loc[result_table.shape[0]] = [X_train_index[index], 'train', 'SVC', y_train[index], train_prediction[index],\n",
    "                                               f1_score(y_train, train_prediction, average='weighted'),\n",
    "                                               roc_auc_score(y_train, train_prediction)]  ######one_hot_encoding 제외\n",
    "print(f'result: {f1=:0.3f}, {auc=:0.3f}')\n",
    "\n",
    "# SVC 추론\n",
    "print('[SVC 검증 데이터]')\n",
    "test_prediction = svc_rbf.predict(X_test)\n",
    "print(f'{y_test=}')\n",
    "print(f'{test_prediction=}')\n",
    "f1 = f1_score(y_test, test_prediction, average='weighted')\n",
    "auc = roc_auc_score(y_test, test_prediction) ######one_hot_encoding 제외\n",
    "for index in range(test_prediction.shape[0]):\n",
    "    result_table.loc[result_table.shape[0]] = [X_test_index[index], 'test', 'SVC', y_test[index], test_prediction[index],\n",
    "                                               f1_score(y_test, test_prediction, average='weighted'),\n",
    "                                               roc_auc_score(y_test, test_prediction)] ######one_hot_encoding 제외\n",
    "print(f'result: {f1=:0.3f}, {auc=:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba5dfb-9080-4c3e-9744-fca1fcedebc9",
   "metadata": {},
   "source": [
    "4-3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa6ef0ff-5083-444c-aa29-f03c8a938e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.856\n",
      "Accuracy: 0.87\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.93      0.89        75\n",
      "         1.0       0.90      0.78      0.84        59\n",
      "\n",
      "    accuracy                           0.87       134\n",
      "   macro avg       0.87      0.86      0.86       134\n",
      "weighted avg       0.87      0.87      0.86       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(data[:, :vector_size + label_size],\n",
    " #                                                   data[:, vector_size + label_size],\n",
    "  #                                                  test_size=test_ratio,\n",
    "   #                                                 stratify=data[:, vector_size + label_size],\n",
    "    #                                                random_state=0)\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 예제 데이터 생성 (여러분은 실제 데이터를 사용해야 합니다.)\n",
    "# X는 문단들의 리스트, y는 해당 문단들의 클래스 레이블\n",
    "#X = [\"문단 1\", \"문단 2\", ..., \"문단 N\"]\n",
    "#y = [1, 2, ..., 15]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 나누기\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest 모델 생성 및 학습\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 정확도 및 분류 보고서 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred, multi_class='ovr')  # 'ovr'은 One-vs-Rest 방식을 사용함\n",
    "print(f'AUC: {auc_score:0.3f}')\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe14e7-b24c-42b7-9a9a-802e567d6c34",
   "metadata": {},
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf294942-3b72-4e51-a5d3-677907e3c855",
   "metadata": {},
   "source": [
    "4-4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ca6d44f-8733-49b0-9b46-8cc8b4a39161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.955\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96        75\n",
      "         1.0       0.95      0.95      0.95        59\n",
      "\n",
      "    accuracy                           0.96       134\n",
      "   macro avg       0.95      0.95      0.95       134\n",
      "weighted avg       0.96      0.96      0.96       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 예제 데이터 생성 (여러분은 실제 데이터를 사용해야 합니다.)\n",
    "# X는 문단들의 리스트, y는 해당 문단들의 클래스 레이블\n",
    "#X = [\"문단 1\", \"문단 2\", ..., \"문단 N\"]\n",
    "#y = [1, 2, ..., 15]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 나누기\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost 모델 생성 및 학습\n",
    "xgb_model = XGBClassifier(objective=\"multi:softmax\", num_class=15, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# 정확도 및 분류 보고서 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred, multi_class='ovr')  # 'ovr'은 One-vs-Rest 방식을 사용함\n",
    "print(f'AUC: {auc_score:0.3f}')\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3298077-82fa-4aca-b7b7-7562d64ec349",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.to_excel('result/result_table_bert.xlsx', index=False)\n",
    "\n",
    "pd.pivot_table(result_table,\n",
    "               values=['f1', 'auc'],\n",
    "               index=['type', 'model'],\n",
    "               aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db323110-bdcb-4fe5-997f-b2bcab493da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(train_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9435621-4351-4e71-88d1-bfcd3986ada2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install torch\n",
    "pip install transformers\n",
    "pip install datasets\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09ba88-a2ad-47ff-a8fc-285b2309bea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"nsmc\")\n",
    "\n",
    "# 데이터셋 전처리\n",
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 학습 및 테스트 데이터 분할\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset['train']['document'],\n",
    "    dataset['train']['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# 데이터셋 인코딩\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# PyTorch Dataset 및 DataLoader 생성\n",
    "train_dataset = NSMCDataset(train_encodings, train_labels)\n",
    "test_dataset = NSMCDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# 테스트\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "# 정확도 및 분류 보고서 출력\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
